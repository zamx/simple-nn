{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "#downloading the MNIST dataset\n",
    "path = untar_data(URLs.MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Path('/home/sam/.fastai/data/mnist_png'),\n",
       " (#2) [Path('/home/sam/.fastai/data/mnist_png/testing'),Path('/home/sam/.fastai/data/mnist_png/training')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path, path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]), torch.Size([60000, 1]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the training datasets ready\n",
    "'''\n",
    "Important info:\n",
    "#training images = 60,000\n",
    "Each of the categories having roughly equal distribution: train_y.unique(return_counts=True)\n",
    "'''\n",
    "train_images_list = get_image_files(path/'training')\n",
    "train_x_list = [tensor(Image.open(img_path)) for img_path in train_images_list]\n",
    "train_y_list = [int(img_path.parent.name) for img_path in train_images_list]\n",
    "train_x = (torch.stack(train_x_list).float()/255).view(-1,28*28)\n",
    "train_y = tensor(train_y_list).view(-1,1)\n",
    "\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "train_dset = list(zip(train_x, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 784]), torch.Size([10000, 1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the validation datasets ready\n",
    "'''\n",
    "Important info:\n",
    "#validation images = 10,000\n",
    "Each of the categories having roughly equal distribution: valid_y.unique(return_counts=True)\n",
    "'''\n",
    "valid_images_list = get_image_files(path/'testing')\n",
    "valid_x_list = [tensor(Image.open(img_path)) for img_path in valid_images_list]\n",
    "valid_y_list = [int(img_path.parent.name) for img_path in valid_images_list]\n",
    "valid_x = (torch.stack(valid_x_list).float()/255).view(-1,28*28)\n",
    "valid_y = tensor(valid_y_list).view(-1,1)\n",
    "\n",
    "valid_x.shape, valid_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dset = list(zip(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "#### Using fastai packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/miniconda3/envs/fastbook/lib/python3.10/site-packages/fastai/vision/learner.py:288: UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code\n",
      "  warn(\"`cnn_learner` has been renamed to `vision_learner` -- please update your code\")\n",
      "/home/sam/miniconda3/envs/fastbook/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/sam/miniconda3/envs/fastbook/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.106589</td>\n",
       "      <td>0.043339</td>\n",
       "      <td>0.987400</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/miniconda3/envs/fastbook/lib/python3.10/site-packages/torch/nn/modules/conv.py:459: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1682343995026/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "#this is just to get a sense of the accuracy using resnet18\n",
    "dls = ImageDataLoaders.from_folder(path, train='training',valid='testing')\n",
    "learn = cnn_learner(dls, resnet18, pretrained=False,\n",
    "                    loss_func=F.cross_entropy, metrics=accuracy, n_out=10)\n",
    "learn.fit_one_cycle(1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "#### Manual SGD & Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_dset, batch_size=256)\n",
    "#valid_dl = DataLoader(valid_dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# function to calculate loss\n",
    "def mnist_loss(pred, actual):\n",
    "    l = nn.CrossEntropyLoss()\n",
    "    return l(pred, actual.squeeze())\n",
    "\n",
    "# function to calculate gradient\n",
    "def calc_grad(xb, yb, model):\n",
    "    pred = model(xb)\n",
    "    loss = mnist_loss(pred, yb)\n",
    "    loss.backward()    \n",
    "    return loss\n",
    "\n",
    "# function to define accuracy\n",
    "def batch_accuracy(pred, actual):\n",
    "    digit_pred = pred.max(dim=1)[1]\n",
    "    return (digit_pred==actual.squeeze()).float().mean()\n",
    "\n",
    "#function to train 1 epoch and print average batch loss\n",
    "def train_epoch(model):\n",
    "    batch_loss = []\n",
    "    for xb,yb in train_dl:\n",
    "        batch_loss.append(calc_grad(xb, yb, model))\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    return tensor(batch_loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "#Optimizer\n",
    "class BasicOptim:\n",
    "    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n",
    "\n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params: p.data -= p.grad.data * self.lr\n",
    "\n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params: p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "#Simple 2 activations function NN\n",
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28,100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1310)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random accuracy\n",
    "batch_accuracy(simple_net(valid_x),valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "opt = BasicOptim(simple_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "#function to train model for multiple epochs\n",
    "def train_model(model,epochs):\n",
    "    print('{:<10}{:<15}{:<15}'.format('Epoch','Training Loss','Validation Accuracy'))\n",
    "    for i in range(epochs):\n",
    "        avg_bl = train_epoch(model)\n",
    "        print('{:<10}{:<15,.2f}{:<15,.2f}'.format(i,avg_bl.item(),batch_accuracy(model(valid_x),valid_y).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "gradient": {},
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     Training Loss  Validation Accuracy\n",
      "0         2.30           0.21           \n",
      "1         2.30           0.26           \n",
      "2         2.29           0.29           \n",
      "3         2.28           0.33           \n",
      "4         2.27           0.37           \n",
      "5         2.27           0.39           \n",
      "6         2.26           0.41           \n",
      "7         2.25           0.41           \n",
      "8         2.24           0.42           \n",
      "9         2.22           0.42           \n",
      "10        2.21           0.42           \n",
      "11        2.20           0.42           \n",
      "12        2.18           0.43           \n",
      "13        2.16           0.43           \n",
      "14        2.14           0.44           \n",
      "15        2.12           0.45           \n",
      "16        2.09           0.46           \n",
      "17        2.06           0.48           \n",
      "18        2.03           0.51           \n",
      "19        1.99           0.53           \n",
      "20        1.95           0.55           \n",
      "21        1.91           0.56           \n",
      "22        1.86           0.57           \n",
      "23        1.81           0.58           \n",
      "24        1.76           0.59           \n",
      "25        1.70           0.60           \n",
      "26        1.64           0.61           \n",
      "27        1.58           0.62           \n",
      "28        1.52           0.63           \n",
      "29        1.46           0.64           \n",
      "30        1.40           0.64           \n",
      "31        1.34           0.65           \n",
      "32        1.28           0.65           \n",
      "33        1.22           0.65           \n",
      "34        1.17           0.65           \n",
      "35        1.12           0.66           \n",
      "36        1.08           0.66           \n",
      "37        1.04           0.66           \n",
      "38        1.00           0.67           \n",
      "39        0.96           0.67           \n",
      "40        0.93           0.67           \n",
      "41        0.90           0.68           \n",
      "42        0.87           0.68           \n",
      "43        0.85           0.68           \n",
      "44        0.82           0.69           \n",
      "45        0.80           0.69           \n",
      "46        0.78           0.69           \n",
      "47        0.76           0.70           \n",
      "48        0.74           0.70           \n",
      "49        0.73           0.70           \n",
      "50        0.71           0.71           \n",
      "51        0.70           0.71           \n",
      "52        0.69           0.72           \n",
      "53        0.67           0.72           \n",
      "54        0.66           0.73           \n",
      "55        0.65           0.73           \n",
      "56        0.64           0.73           \n",
      "57        0.63           0.74           \n",
      "58        0.62           0.74           \n",
      "59        0.61           0.75           \n",
      "60        0.60           0.75           \n",
      "61        0.59           0.75           \n",
      "62        0.58           0.76           \n",
      "63        0.58           0.76           \n",
      "64        0.57           0.76           \n",
      "65        0.56           0.76           \n",
      "66        0.55           0.77           \n",
      "67        0.55           0.77           \n",
      "68        0.54           0.77           \n",
      "69        0.54           0.78           \n",
      "70        0.53           0.78           \n",
      "71        0.52           0.78           \n",
      "72        0.52           0.79           \n",
      "73        0.51           0.79           \n",
      "74        0.51           0.79           \n",
      "75        0.50           0.79           \n",
      "76        0.50           0.80           \n",
      "77        0.49           0.80           \n",
      "78        0.49           0.80           \n",
      "79        0.48           0.80           \n",
      "80        0.48           0.81           \n",
      "81        0.47           0.81           \n",
      "82        0.47           0.81           \n",
      "83        0.46           0.81           \n",
      "84        0.46           0.82           \n",
      "85        0.46           0.82           \n",
      "86        0.45           0.82           \n",
      "87        0.45           0.82           \n",
      "88        0.44           0.82           \n",
      "89        0.44           0.83           \n",
      "90        0.44           0.83           \n",
      "91        0.43           0.83           \n",
      "92        0.43           0.83           \n",
      "93        0.43           0.83           \n",
      "94        0.43           0.83           \n",
      "95        0.42           0.84           \n",
      "96        0.42           0.84           \n",
      "97        0.42           0.84           \n",
      "98        0.41           0.84           \n",
      "99        0.41           0.84           \n"
     ]
    }
   ],
   "source": [
    "#model training call\n",
    "train_model(simple_net, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastbook",
   "language": "python",
   "name": "fastbook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
